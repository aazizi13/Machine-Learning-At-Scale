{"cells":[{"cell_type":"markdown","source":["# DO NOT RUN OR EDIT CODE IN THE SHARED FOLDER"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bd4dc3f2-c57a-4102-9351-73ee7ca49ec8","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import os\nimport sys\nimport itertools\nfrom multiprocessing.pool import ThreadPool\n\nimport numpy as np\n\nfrom pyspark import keyword_only, since, SparkContext, inheritable_thread_target\nfrom pyspark.ml import Estimator, Transformer, Model\nfrom pyspark.ml.common import inherit_doc, _py2java, _java2py\nfrom pyspark.ml.evaluation import Evaluator\nfrom pyspark.ml.param import Params, Param, TypeConverters\nfrom pyspark.ml.param.shared import HasCollectSubModels, HasParallelism, HasSeed\nfrom pyspark.ml.util import DefaultParamsReader, DefaultParamsWriter, MetaAlgorithmReadWrite, \\\n    MLReadable, MLReader, MLWritable, MLWriter, JavaMLReader, JavaMLWriter\nfrom pyspark.ml.wrapper import JavaParams, JavaEstimator, JavaWrapper\nfrom pyspark.sql.functions import col, lit, rand, UserDefinedFunction\nfrom pyspark.sql.types import BooleanType\n\n__all__ = ['ParamGridBuilder', 'CrossValidator', 'CrossValidatorModel', 'TrainValidationSplit',\n           'TrainValidationSplitModel']\n\n\ndef _parallelFitTasks(est, train, eva, validation, epm, collectSubModel=False):\n    \"\"\"\n    Creates a list of callables which can be called from different threads to fit and evaluate\n    an estimator in parallel. Each callable returns an `(index, metric)` pair.\n\n    Parameters\n    ----------\n    est : :py:class:`pyspark.ml.baseEstimator`\n        he estimator to be fit.\n    train : :py:class:`pyspark.sql.DataFrame`\n        DataFrame, training data set, used for fitting.\n    eva : :py:class:`pyspark.ml.evaluation.Evaluator`\n        used to compute `metric`\n    validation : :py:class:`pyspark.sql.DataFrame`\n        DataFrame, validation data set, used for evaluation.\n    epm : :py:class:`collections.abc.Sequence`\n        Sequence of ParamMap, params maps to be used during fitting & evaluation.\n    collectSubModel : bool\n        Whether to collect sub model.\n\n    Returns\n    -------\n    tuple\n        (int, float, subModel), an index into `epm` and the associated metric value.\n    \"\"\"\n    modelIter = est.fitMultiple(train, epm)\n\n    def singleTask():\n        index, model = next(modelIter)\n        # TODO: duplicate evaluator to take extra params from input\n        #  Note: Supporting tuning params in evaluator need update method\n        #  `MetaAlgorithmReadWrite.getAllNestedStages`, make it return\n        #  all nested stages and evaluators\n        metric = eva.evaluate(model.transform(validation, epm[index]))\n        return index, metric, model if collectSubModel else None\n\n    return [singleTask] * len(epm)\n\n\nclass ParamGridBuilder(object):\n    r\"\"\"\n    Builder for a param grid used in grid search-based model selection.\n\n\n    .. versionadded:: 1.4.0\n\n    Examples\n    --------\n    >>> from pyspark.ml.classification import LogisticRegression\n    >>> lr = LogisticRegression()\n    >>> output = ParamGridBuilder() \\\n    ...     .baseOn({lr.labelCol: 'l'}) \\\n    ...     .baseOn([lr.predictionCol, 'p']) \\\n    ...     .addGrid(lr.regParam, [1.0, 2.0]) \\\n    ...     .addGrid(lr.maxIter, [1, 5]) \\\n    ...     .build()\n    >>> expected = [\n    ...     {lr.regParam: 1.0, lr.maxIter: 1, lr.labelCol: 'l', lr.predictionCol: 'p'},\n    ...     {lr.regParam: 2.0, lr.maxIter: 1, lr.labelCol: 'l', lr.predictionCol: 'p'},\n    ...     {lr.regParam: 1.0, lr.maxIter: 5, lr.labelCol: 'l', lr.predictionCol: 'p'},\n    ...     {lr.regParam: 2.0, lr.maxIter: 5, lr.labelCol: 'l', lr.predictionCol: 'p'}]\n    >>> len(output) == len(expected)\n    True\n    >>> all([m in expected for m in output])\n    True\n    \"\"\"\n\n    def __init__(self):\n        self._param_grid = {}\n\n    @since(\"1.4.0\")\n    def addGrid(self, param, values):\n        \"\"\"\n        Sets the given parameters in this grid to fixed values.\n\n        param must be an instance of Param associated with an instance of Params\n        (such as Estimator or Transformer).\n        \"\"\"\n        if isinstance(param, Param):\n            self._param_grid[param] = values\n        else:\n            raise TypeError(\"param must be an instance of Param\")\n\n        return self\n\n\n    @since(\"1.4.0\")\n    def baseOn(self, *args):\n        \"\"\"\n        Sets the given parameters in this grid to fixed values.\n        Accepts either a parameter dictionary or a list of (parameter, value) pairs.\n        \"\"\"\n        if isinstance(args[0], dict):\n            self.baseOn(*args[0].items())\n        else:\n            for (param, value) in args:\n                self.addGrid(param, [value])\n\n        return self\n\n\n    @since(\"1.4.0\")\n    def build(self):\n        \"\"\"\n        Builds and returns all combinations of parameters specified\n        by the param grid.\n        \"\"\"\n        keys = self._param_grid.keys()\n        grid_values = self._param_grid.values()\n\n        def to_key_value_pairs(keys, values):\n            return [(key, key.typeConverter(value)) for key, value in zip(keys, values)]\n\n        return [dict(to_key_value_pairs(keys, prod)) for prod in itertools.product(*grid_values)]\n\n\n\nclass _ValidatorParams(HasSeed):\n    \"\"\"\n    Common params for TrainValidationSplit and CrossValidator.\n    \"\"\"\n\n    estimator = Param(Params._dummy(), \"estimator\", \"estimator to be cross-validated\")\n    estimatorParamMaps = Param(Params._dummy(), \"estimatorParamMaps\", \"estimator param maps\")\n    evaluator = Param(\n        Params._dummy(), \"evaluator\",\n        \"evaluator used to select hyper-parameters that maximize the validator metric\")\n\n    @since(\"2.0.0\")\n    def getEstimator(self):\n        \"\"\"\n        Gets the value of estimator or its default value.\n        \"\"\"\n        return self.getOrDefault(self.estimator)\n\n    @since(\"2.0.0\")\n    def getEstimatorParamMaps(self):\n        \"\"\"\n        Gets the value of estimatorParamMaps or its default value.\n        \"\"\"\n        return self.getOrDefault(self.estimatorParamMaps)\n\n    @since(\"2.0.0\")\n    def getEvaluator(self):\n        \"\"\"\n        Gets the value of evaluator or its default value.\n        \"\"\"\n        return self.getOrDefault(self.evaluator)\n\n    @classmethod\n    def _from_java_impl(cls, java_stage):\n        \"\"\"\n        Return Python estimator, estimatorParamMaps, and evaluator from a Java ValidatorParams.\n        \"\"\"\n\n        # Load information from java_stage to the instance.\n        estimator = JavaParams._from_java(java_stage.getEstimator())\n        evaluator = JavaParams._from_java(java_stage.getEvaluator())\n        if isinstance(estimator, JavaEstimator):\n            epms = [estimator._transfer_param_map_from_java(epm)\n                    for epm in java_stage.getEstimatorParamMaps()]\n        elif MetaAlgorithmReadWrite.isMetaEstimator(estimator):\n            # Meta estimator such as Pipeline, OneVsRest\n            epms = _ValidatorSharedReadWrite.meta_estimator_transfer_param_maps_from_java(\n                estimator, java_stage.getEstimatorParamMaps())\n        else:\n            raise ValueError('Unsupported estimator used in tuning: ' + str(estimator))\n\n        return estimator, epms, evaluator\n\n    def _to_java_impl(self):\n        \"\"\"\n        Return Java estimator, estimatorParamMaps, and evaluator from this Python instance.\n        \"\"\"\n\n        gateway = SparkContext._gateway\n        cls = SparkContext._jvm.org.apache.spark.ml.param.ParamMap\n\n        estimator = self.getEstimator()\n        if isinstance(estimator, JavaEstimator):\n            java_epms = gateway.new_array(cls, len(self.getEstimatorParamMaps()))\n            for idx, epm in enumerate(self.getEstimatorParamMaps()):\n                java_epms[idx] = self.getEstimator()._transfer_param_map_to_java(epm)\n        elif MetaAlgorithmReadWrite.isMetaEstimator(estimator):\n            # Meta estimator such as Pipeline, OneVsRest\n            java_epms = _ValidatorSharedReadWrite.meta_estimator_transfer_param_maps_to_java(\n                estimator, self.getEstimatorParamMaps())\n        else:\n            raise ValueError('Unsupported estimator used in tuning: ' + str(estimator))\n\n        java_estimator = self.getEstimator()._to_java()\n        java_evaluator = self.getEvaluator()._to_java()\n        return java_estimator, java_epms, java_evaluator\n\n\nclass _ValidatorSharedReadWrite:\n\n    @staticmethod\n    def meta_estimator_transfer_param_maps_to_java(pyEstimator, pyParamMaps):\n        pyStages = MetaAlgorithmReadWrite.getAllNestedStages(pyEstimator)\n        stagePairs = list(map(lambda stage: (stage, stage._to_java()), pyStages))\n        sc = SparkContext._active_spark_context\n\n        paramMapCls = SparkContext._jvm.org.apache.spark.ml.param.ParamMap\n        javaParamMaps = SparkContext._gateway.new_array(paramMapCls, len(pyParamMaps))\n\n        for idx, pyParamMap in enumerate(pyParamMaps):\n            javaParamMap = JavaWrapper._new_java_obj(\"org.apache.spark.ml.param.ParamMap\")\n            for pyParam, pyValue in pyParamMap.items():\n                javaParam = None\n                for pyStage, javaStage in stagePairs:\n                    if pyStage._testOwnParam(pyParam.parent, pyParam.name):\n                        javaParam = javaStage.getParam(pyParam.name)\n                        break\n                if javaParam is None:\n                    raise ValueError('Resolve param in estimatorParamMaps failed: ' + str(pyParam))\n                if isinstance(pyValue, Params) and hasattr(pyValue, \"_to_java\"):\n                    javaValue = pyValue._to_java()\n                else:\n                    javaValue = _py2java(sc, pyValue)\n                pair = javaParam.w(javaValue)\n                javaParamMap.put([pair])\n            javaParamMaps[idx] = javaParamMap\n        return javaParamMaps\n\n    @staticmethod\n    def meta_estimator_transfer_param_maps_from_java(pyEstimator, javaParamMaps):\n        pyStages = MetaAlgorithmReadWrite.getAllNestedStages(pyEstimator)\n        stagePairs = list(map(lambda stage: (stage, stage._to_java()), pyStages))\n        sc = SparkContext._active_spark_context\n        pyParamMaps = []\n        for javaParamMap in javaParamMaps:\n            pyParamMap = dict()\n            for javaPair in javaParamMap.toList():\n                javaParam = javaPair.param()\n                pyParam = None\n                for pyStage, javaStage in stagePairs:\n                    if pyStage._testOwnParam(javaParam.parent(), javaParam.name()):\n                        pyParam = pyStage.getParam(javaParam.name())\n                if pyParam is None:\n                    raise ValueError('Resolve param in estimatorParamMaps failed: ' +\n                                     javaParam.parent() + '.' + javaParam.name())\n                javaValue = javaPair.value()\n                if sc._jvm.Class.forName(\"org.apache.spark.ml.util.DefaultParamsWritable\") \\\n                        .isInstance(javaValue):\n                    pyValue = JavaParams._from_java(javaValue)\n                else:\n                    pyValue = _java2py(sc, javaValue)\n                pyParamMap[pyParam] = pyValue\n            pyParamMaps.append(pyParamMap)\n        return pyParamMaps\n\n    @staticmethod\n    def is_java_convertible(instance):\n        allNestedStages = MetaAlgorithmReadWrite.getAllNestedStages(instance.getEstimator())\n        evaluator_convertible = isinstance(instance.getEvaluator(), JavaParams)\n        estimator_convertible = all(map(lambda stage: hasattr(stage, '_to_java'), allNestedStages))\n        return estimator_convertible and evaluator_convertible\n\n    @staticmethod\n    def saveImpl(path, instance, sc, extraMetadata=None):\n        numParamsNotJson = 0\n        jsonEstimatorParamMaps = []\n        for paramMap in instance.getEstimatorParamMaps():\n            jsonParamMap = []\n            for p, v in paramMap.items():\n                jsonParam = {'parent': p.parent, 'name': p.name}\n                if (isinstance(v, Estimator) and not MetaAlgorithmReadWrite.isMetaEstimator(v)) \\\n                        or isinstance(v, Transformer) or isinstance(v, Evaluator):\n                    relative_path = f'epm_{p.name}{numParamsNotJson}'\n                    param_path = os.path.join(path, relative_path)\n                    numParamsNotJson += 1\n                    v.save(param_path)\n                    jsonParam['value'] = relative_path\n                    jsonParam['isJson'] = False\n                elif isinstance(v, MLWritable):\n                    raise RuntimeError(\n                        \"ValidatorSharedReadWrite.saveImpl does not handle parameters of type: \"\n                        \"MLWritable that are not Estimaor/Evaluator/Transformer, and if parameter \"\n                        \"is estimator, it cannot be meta estimator such as Validator or OneVsRest\")\n                else:\n                    jsonParam['value'] = v\n                    jsonParam['isJson'] = True\n                jsonParamMap.append(jsonParam)\n            jsonEstimatorParamMaps.append(jsonParamMap)\n\n        skipParams = ['estimator', 'evaluator', 'estimatorParamMaps']\n        jsonParams = DefaultParamsWriter.extractJsonParams(instance, skipParams)\n        jsonParams['estimatorParamMaps'] = jsonEstimatorParamMaps\n\n        DefaultParamsWriter.saveMetadata(instance, path, sc, extraMetadata, jsonParams)\n        evaluatorPath = os.path.join(path, 'evaluator')\n        instance.getEvaluator().save(evaluatorPath)\n        estimatorPath = os.path.join(path, 'estimator')\n        instance.getEstimator().save(estimatorPath)\n\n    @staticmethod\n    def load(path, sc, metadata):\n        evaluatorPath = os.path.join(path, 'evaluator')\n        evaluator = DefaultParamsReader.loadParamsInstance(evaluatorPath, sc)\n        estimatorPath = os.path.join(path, 'estimator')\n        estimator = DefaultParamsReader.loadParamsInstance(estimatorPath, sc)\n\n        uidToParams = MetaAlgorithmReadWrite.getUidMap(estimator)\n        uidToParams[evaluator.uid] = evaluator\n\n        jsonEstimatorParamMaps = metadata['paramMap']['estimatorParamMaps']\n\n        estimatorParamMaps = []\n        for jsonParamMap in jsonEstimatorParamMaps:\n            paramMap = {}\n            for jsonParam in jsonParamMap:\n                est = uidToParams[jsonParam['parent']]\n                param = getattr(est, jsonParam['name'])\n                if 'isJson' not in jsonParam or ('isJson' in jsonParam and jsonParam['isJson']):\n                    value = jsonParam['value']\n                else:\n                    relativePath = jsonParam['value']\n                    valueSavedPath = os.path.join(path, relativePath)\n                    value = DefaultParamsReader.loadParamsInstance(valueSavedPath, sc)\n                paramMap[param] = value\n            estimatorParamMaps.append(paramMap)\n\n        return metadata, estimator, evaluator, estimatorParamMaps\n\n    @staticmethod\n    def validateParams(instance):\n        estiamtor = instance.getEstimator()\n        evaluator = instance.getEvaluator()\n        uidMap = MetaAlgorithmReadWrite.getUidMap(estiamtor)\n\n        for elem in [evaluator] + list(uidMap.values()):\n            if not isinstance(elem, MLWritable):\n                raise ValueError(f'Validator write will fail because it contains {elem.uid} '\n                                 f'which is not writable.')\n\n        estimatorParamMaps = instance.getEstimatorParamMaps()\n        paramErr = 'Validator save requires all Params in estimatorParamMaps to apply to ' \\\n                   f'its Estimator, An extraneous Param was found: '\n        for paramMap in estimatorParamMaps:\n            for param in paramMap:\n                if param.parent not in uidMap:\n                    raise ValueError(paramErr + repr(param))\n\n    @staticmethod\n    def getValidatorModelWriterPersistSubModelsParam(writer):\n        if 'persistsubmodels' in writer.optionMap:\n            persistSubModelsParam = writer.optionMap['persistsubmodels'].lower()\n            if persistSubModelsParam == 'true':\n                return True\n            elif persistSubModelsParam == 'false':\n                return False\n            else:\n                raise ValueError(\n                    f'persistSubModels option value {persistSubModelsParam} is invalid, '\n                    f\"the possible values are True, 'True' or False, 'False'\")\n        else:\n            return writer.instance.subModels is not None\n\n\n_save_with_persist_submodels_no_submodels_found_err = \\\n    'When persisting tuning models, you can only set persistSubModels to true if the tuning ' \\\n    'was done with collectSubModels set to true. To save the sub-models, try rerunning fitting ' \\\n    'with collectSubModels set to true.'\n\n\n@inherit_doc\nclass CrossValidatorReader(MLReader):\n\n    def __init__(self, cls):\n        super(CrossValidatorReader, self).__init__()\n        self.cls = cls\n\n    def load(self, path):\n        metadata = DefaultParamsReader.loadMetadata(path, self.sc)\n        if not DefaultParamsReader.isPythonParamsInstance(metadata):\n            return JavaMLReader(self.cls).load(path)\n        else:\n            metadata, estimator, evaluator, estimatorParamMaps = \\\n                _ValidatorSharedReadWrite.load(path, self.sc, metadata)\n            cv = CrossValidator(estimator=estimator,\n                                estimatorParamMaps=estimatorParamMaps,\n                                evaluator=evaluator)\n            cv = cv._resetUid(metadata['uid'])\n            DefaultParamsReader.getAndSetParams(cv, metadata, skipParams=['estimatorParamMaps'])\n            return cv\n\n\n@inherit_doc\nclass CrossValidatorWriter(MLWriter):\n\n    def __init__(self, instance):\n        super(CrossValidatorWriter, self).__init__()\n        self.instance = instance\n\n    def saveImpl(self, path):\n        _ValidatorSharedReadWrite.validateParams(self.instance)\n        _ValidatorSharedReadWrite.saveImpl(path, self.instance, self.sc)\n\n\n@inherit_doc\nclass CrossValidatorModelReader(MLReader):\n\n    def __init__(self, cls):\n        super(CrossValidatorModelReader, self).__init__()\n        self.cls = cls\n\n    def load(self, path):\n        metadata = DefaultParamsReader.loadMetadata(path, self.sc)\n        if not DefaultParamsReader.isPythonParamsInstance(metadata):\n            return JavaMLReader(self.cls).load(path)\n        else:\n            metadata, estimator, evaluator, estimatorParamMaps = \\\n                _ValidatorSharedReadWrite.load(path, self.sc, metadata)\n            numFolds = metadata['paramMap']['numFolds']\n            bestModelPath = os.path.join(path, 'bestModel')\n            bestModel = DefaultParamsReader.loadParamsInstance(bestModelPath, self.sc)\n            avgMetrics = metadata['avgMetrics']\n            persistSubModels = ('persistSubModels' in metadata) and metadata['persistSubModels']\n\n            if persistSubModels:\n                subModels = [[None] * len(estimatorParamMaps)] * numFolds\n                for splitIndex in range(numFolds):\n                    for paramIndex in range(len(estimatorParamMaps)):\n                        modelPath = os.path.join(\n                            path, 'subModels', f'fold{splitIndex}', f'{paramIndex}')\n                        subModels[splitIndex][paramIndex] = \\\n                            DefaultParamsReader.loadParamsInstance(modelPath, self.sc)\n            else:\n                subModels = None\n\n            cvModel = CrossValidatorModel(bestModel, avgMetrics=avgMetrics, subModels=subModels)\n            cvModel = cvModel._resetUid(metadata['uid'])\n            cvModel.set(cvModel.estimator, estimator)\n            cvModel.set(cvModel.estimatorParamMaps, estimatorParamMaps)\n            cvModel.set(cvModel.evaluator, evaluator)\n            DefaultParamsReader.getAndSetParams(\n                cvModel, metadata, skipParams=['estimatorParamMaps'])\n            return cvModel\n\n\n@inherit_doc\nclass CrossValidatorModelWriter(MLWriter):\n\n    def __init__(self, instance):\n        super(CrossValidatorModelWriter, self).__init__()\n        self.instance = instance\n\n    def saveImpl(self, path):\n        _ValidatorSharedReadWrite.validateParams(self.instance)\n        instance = self.instance\n        persistSubModels = _ValidatorSharedReadWrite \\\n            .getValidatorModelWriterPersistSubModelsParam(self)\n        extraMetadata = {'avgMetrics': instance.avgMetrics,\n                         'persistSubModels': persistSubModels}\n        _ValidatorSharedReadWrite.saveImpl(path, instance, self.sc, extraMetadata=extraMetadata)\n        bestModelPath = os.path.join(path, 'bestModel')\n        instance.bestModel.save(bestModelPath)\n        if persistSubModels:\n            if instance.subModels is None:\n                raise ValueError(_save_with_persist_submodels_no_submodels_found_err)\n            subModelsPath = os.path.join(path, 'subModels')\n            for splitIndex in range(instance.getNumFolds()):\n                splitPath = os.path.join(subModelsPath, f'fold{splitIndex}')\n                for paramIndex in range(len(instance.getEstimatorParamMaps())):\n                    modelPath = os.path.join(splitPath, f'{paramIndex}')\n                    instance.subModels[splitIndex][paramIndex].save(modelPath)\n\n\nclass _CrossValidatorParams(_ValidatorParams):\n    \"\"\"\n    Params for :py:class:`CrossValidator` and :py:class:`CrossValidatorModel`.\n\n    .. versionadded:: 3.0.0\n    \"\"\"\n\n    numFolds = Param(Params._dummy(), \"numFolds\", \"number of folds for cross validation\",\n                     typeConverter=TypeConverters.toInt)\n\n    foldCol = Param(Params._dummy(), \"foldCol\", \"Param for the column name of user \" +\n                    \"specified fold number. Once this is specified, :py:class:`CrossValidator` \" +\n                    \"won't do random k-fold split. Note that this column should be integer type \" +\n                    \"with range [0, numFolds) and Spark will throw exception on out-of-range \" +\n                    \"fold numbers.\", typeConverter=TypeConverters.toString)\n\n    def __init__(self, *args):\n        super(_CrossValidatorParams, self).__init__(*args)\n        self._setDefault(numFolds=3, foldCol=\"\")\n\n    @since(\"1.4.0\")\n    def getNumFolds(self):\n        \"\"\"\n        Gets the value of numFolds or its default value.\n        \"\"\"\n        return self.getOrDefault(self.numFolds)\n\n    @since(\"3.1.0\")\n    def getFoldCol(self):\n        \"\"\"\n        Gets the value of foldCol or its default value.\n        \"\"\"\n        return self.getOrDefault(self.foldCol)\n\n\nclass CustomCrossValidator(Estimator, _CrossValidatorParams, HasParallelism, HasCollectSubModels,\n                     MLReadable, MLWritable):\n    \"\"\"\n    Modifies CrossValidator allowing custom train and test dataset to be passed into the function\n    Bypass generation of train/test via numFolds\n    instead train and test set is user define\n    \"\"\"\n    \n    splitWord = Param(Params._dummy(), \"splitWord\", \"Tuple to split train and test set e.g. ('train', 'test')\",\n                      typeConverter=TypeConverters.toListString)\n    cvCol = Param(Params._dummy(), \"cvCol\", \"Column name to filter train and test list\",\n                      typeConverter=TypeConverters.toString)\n\n    @keyword_only\n    def __init__(self, *, estimator=None, estimatorParamMaps=None, evaluator=None, seed=None, parallelism=1, collectSubModels=False, \n                 splitWord = ('train', 'test'), cvCol = 'cv'):\n        \"\"\"\n        __init__(self, \\\\*, estimator=None, estimatorParamMaps=None, evaluator=None, numFolds=3,\\\n                 seed=None, parallelism=1, collectSubModels=False, foldCol=\"\")\n        \"\"\"\n        super(CustomCrossValidator, self).__init__()\n        self._setDefault(parallelism=1)\n        kwargs = self._input_kwargs\n        self._set(**kwargs)\n\n    @keyword_only\n    @since(\"1.4.0\")\n    def setParams(self, *, estimator=None, estimatorParamMaps=None, evaluator=None, seed=None, parallelism=1, collectSubModels=False, \n                 splitWord = ('train', 'test'), cvCol = 'cv'):\n        \"\"\"\n        Sets params for cross validator.\n        \"\"\"\n        kwargs = self._input_kwargs\n        return self._set(**kwargs)\n\n\n    @since(\"2.0.0\")\n    def setEstimator(self, value):\n        \"\"\"\n        Sets the value of :py:attr:`estimator`.\n        \"\"\"\n        return self._set(estimator=value)\n\n\n    @since(\"2.0.0\")\n    def setEstimatorParamMaps(self, value):\n        \"\"\"\n        Sets the value of :py:attr:`estimatorParamMaps`.\n        \"\"\"\n        return self._set(estimatorParamMaps=value)\n\n\n    @since(\"2.0.0\")\n    def setEvaluator(self, value):\n        \"\"\"\n        Sets the value of :py:attr:`evaluator`.\n        \"\"\"\n        return self._set(evaluator=value)\n\n\n    @since(\"1.4.0\")\n    def setNumFolds(self, value):\n        \"\"\"\n        Sets the value of :py:attr:`numFolds`.\n        \"\"\"\n        return self._set(numFolds=value)\n\n\n    @since(\"3.1.0\")\n    def setFoldCol(self, value):\n        \"\"\"\n        Sets the value of :py:attr:`foldCol`.\n        \"\"\"\n        return self._set(foldCol=value)\n\n\n    def setSeed(self, value):\n        \"\"\"\n        Sets the value of :py:attr:`seed`.\n        \"\"\"\n        return self._set(seed=value)\n\n\n    def setParallelism(self, value):\n        \"\"\"\n        Sets the value of :py:attr:`parallelism`.\n        \"\"\"\n        return self._set(parallelism=value)\n\n\n    def setCollectSubModels(self, value):\n        \"\"\"\n        Sets the value of :py:attr:`collectSubModels`.\n        \"\"\"\n        return self._set(collectSubModels=value)\n\n\n    def _fit(self, dataset):\n        est = self.getOrDefault(self.estimator)\n        epm = self.getOrDefault(self.estimatorParamMaps)\n        numModels = len(epm)\n        eva = self.getOrDefault(self.evaluator)\n        nFolds = len(dataset)\n        seed = self.getOrDefault(self.seed)\n        metrics = [0.0] * numModels\n        matrix_metrics = [[0 for x in range(nFolds)] for y in range(len(epm))]\n\n        # pool = ThreadPool(processes=min(self.getParallelism(), numModels))\n        if self.getParallelism() < numModels:\n            min_value = self.getParallelism()\n        else:\n            min_value = numModels\n        pool = ThreadPool(processes=min_value)\n\n        for i in range(nFolds):\n            validation = dataset[list(dataset.keys())[i]].filter(col(self.getOrDefault(self.cvCol))==(self.getOrDefault(self.splitWord))[0]).cache()\n            train = dataset[list(dataset.keys())[i]].filter(col(self.getOrDefault(self.cvCol))==(self.getOrDefault(self.splitWord))[1]).cache()\n\n            print('fold {} start...'.format(i+1))\n            tasks = _parallelFitTasks(est, train, eva, validation, epm)\n            for j, metric, subModel in pool.imap_unordered(lambda f: f(), tasks):\n                #print(j, metric)\n                matrix_metrics[j][i] = metric\n                metrics[j] += (metric / nFolds)\n            print('fold {} end'.format(i+1))\n            #print(metrics)\n            validation.unpersist()\n            train.unpersist()\n\n        if eva.isLargerBetter():\n            bestIndex = np.argmax(metrics)\n        else:\n            bestIndex = np.argmin(metrics)\n\n#         for i in range(len(metrics)):\n#             print(epm[i], 'Detailed Score {}'.format(matrix_metrics[i]), 'Avg Score {}'.format(metrics[i]))\n\n        print('Best Model: ', epm[bestIndex], 'Detailed Score {}'.format(matrix_metrics[bestIndex]),\n              'Avg Score {}'.format(metrics[bestIndex]))\n\n        ### Do not bother to train on full dataset, just the latest train supplied\n        # bestModel = est.fit(dataset, epm[bestIndex])\n        bestModel = est.fit(train, epm[bestIndex])\n        return self._copyValues(CrossValidatorModel(bestModel, metrics))\n\n    def copy(self, extra=None):\n        \"\"\"\n        Creates a copy of this instance with a randomly generated uid\n        and some extra params. This copies creates a deep copy of\n        the embedded paramMap, and copies the embedded and extra parameters over.\n\n\n        .. versionadded:: 1.4.0\n\n        Parameters\n        ----------\n        extra : dict, optional\n            Extra parameters to copy to the new instance\n\n        Returns\n        -------\n        :py:class:`CrossValidator`\n            Copy of this instance\n        \"\"\"\n        if extra is None:\n            extra = dict()\n        newCV = Params.copy(self, extra)\n        if self.isSet(self.estimator):\n            newCV.setEstimator(self.getEstimator().copy(extra))\n        # estimatorParamMaps remain the same\n        if self.isSet(self.evaluator):\n            newCV.setEvaluator(self.getEvaluator().copy(extra))\n        return newCV\n\n\n    @since(\"2.3.0\")\n    def write(self):\n        \"\"\"Returns an MLWriter instance for this ML instance.\"\"\"\n        if _ValidatorSharedReadWrite.is_java_convertible(self):\n            return JavaMLWriter(self)\n        return CrossValidatorWriter(self)\n\n\n    @classmethod\n    @since(\"2.3.0\")\n    def read(cls):\n        \"\"\"Returns an MLReader instance for this class.\"\"\"\n        return CrossValidatorReader(cls)\n\n\n    @classmethod\n    def _from_java(cls, java_stage):\n        \"\"\"\n        Given a Java CrossValidator, create and return a Python wrapper of it.\n        Used for ML persistence.\n        \"\"\"\n\n        estimator, epms, evaluator = super(CrossValidator, cls)._from_java_impl(java_stage)\n        numFolds = java_stage.getNumFolds()\n        seed = java_stage.getSeed()\n        parallelism = java_stage.getParallelism()\n        collectSubModels = java_stage.getCollectSubModels()\n        foldCol = java_stage.getFoldCol()\n        # Create a new instance of this stage.\n        py_stage = cls(estimator=estimator, estimatorParamMaps=epms, evaluator=evaluator,\n                       numFolds=numFolds, seed=seed, parallelism=parallelism,\n                       collectSubModels=collectSubModels, foldCol=foldCol)\n        py_stage._resetUid(java_stage.uid())\n        return py_stage\n\n    def _to_java(self):\n        \"\"\"\n        Transfer this instance to a Java CrossValidator. Used for ML persistence.\n\n        Returns\n        -------\n        py4j.java_gateway.JavaObject\n            Java object equivalent to this instance.\n        \"\"\"\n\n        estimator, epms, evaluator = super(CrossValidator, self)._to_java_impl()\n\n        _java_obj = JavaParams._new_java_obj(\"org.apache.spark.ml.tuning.CrossValidator\", self.uid)\n        _java_obj.setEstimatorParamMaps(epms)\n        _java_obj.setEvaluator(evaluator)\n        _java_obj.setEstimator(estimator)\n        _java_obj.setSeed(self.getSeed())\n        _java_obj.setNumFolds(self.getNumFolds())\n        _java_obj.setParallelism(self.getParallelism())\n        _java_obj.setCollectSubModels(self.getCollectSubModels())\n        _java_obj.setFoldCol(self.getFoldCol())\n\n        return _java_obj\n\n\n\nclass CrossValidatorModel(Model, _CrossValidatorParams, MLReadable, MLWritable):\n    \"\"\"\n\n    CrossValidatorModel contains the model with the highest average cross-validation\n    metric across folds and uses this model to transform input data. CrossValidatorModel\n    also tracks the metrics for each param map evaluated.\n\n    .. versionadded:: 1.4.0\n    \"\"\"\n\n    def __init__(self, bestModel, avgMetrics=None, subModels=None):\n        super(CrossValidatorModel, self).__init__()\n        #: best model from cross validation\n        self.bestModel = bestModel\n        #: Average cross-validation metrics for each paramMap in\n        #: CrossValidator.estimatorParamMaps, in the corresponding order.\n        self.avgMetrics = avgMetrics or []\n        #: sub model list from cross validation\n        self.subModels = subModels\n\n    def _transform(self, dataset):\n        return self.bestModel.transform(dataset)\n\n    def copy(self, extra=None):\n        \"\"\"\n        Creates a copy of this instance with a randomly generated uid\n        and some extra params. This copies the underlying bestModel,\n        creates a deep copy of the embedded paramMap, and\n        copies the embedded and extra parameters over.\n        It does not copy the extra Params into the subModels.\n\n        .. versionadded:: 1.4.0\n\n        Parameters\n        ----------\n        extra : dict, optional\n            Extra parameters to copy to the new instance\n\n        Returns\n        -------\n        :py:class:`CrossValidatorModel`\n            Copy of this instance\n        \"\"\"\n        if extra is None:\n            extra = dict()\n        bestModel = self.bestModel.copy(extra)\n        avgMetrics = list(self.avgMetrics)\n        subModels = [\n            [sub_model.copy() for sub_model in fold_sub_models]\n            for fold_sub_models in self.subModels\n        ]\n        return self._copyValues(CrossValidatorModel(bestModel, avgMetrics, subModels), extra=extra)\n\n\n    @since(\"2.3.0\")\n    def write(self):\n        \"\"\"Returns an MLWriter instance for this ML instance.\"\"\"\n        if _ValidatorSharedReadWrite.is_java_convertible(self):\n            return JavaMLWriter(self)\n        return CrossValidatorModelWriter(self)\n\n\n    @classmethod\n    @since(\"2.3.0\")\n    def read(cls):\n        \"\"\"Returns an MLReader instance for this class.\"\"\"\n        return CrossValidatorModelReader(cls)\n\n\n    @classmethod\n    def _from_java(cls, java_stage):\n        \"\"\"\n        Given a Java CrossValidatorModel, create and return a Python wrapper of it.\n        Used for ML persistence.\n        \"\"\"\n        sc = SparkContext._active_spark_context\n        bestModel = JavaParams._from_java(java_stage.bestModel())\n        avgMetrics = _java2py(sc, java_stage.avgMetrics())\n        estimator, epms, evaluator = super(CrossValidatorModel, cls)._from_java_impl(java_stage)\n\n        py_stage = cls(bestModel=bestModel, avgMetrics=avgMetrics)\n        params = {\n            \"evaluator\": evaluator,\n            \"estimator\": estimator,\n            \"estimatorParamMaps\": epms,\n            \"numFolds\": java_stage.getNumFolds(),\n            \"foldCol\": java_stage.getFoldCol(),\n            \"seed\": java_stage.getSeed(),\n        }\n        for param_name, param_val in params.items():\n            py_stage = py_stage._set(**{param_name: param_val})\n\n        if java_stage.hasSubModels():\n            py_stage.subModels = [[JavaParams._from_java(sub_model)\n                                   for sub_model in fold_sub_models]\n                                  for fold_sub_models in java_stage.subModels()]\n\n        py_stage._resetUid(java_stage.uid())\n        return py_stage\n\n    def _to_java(self):\n        \"\"\"\n        Transfer this instance to a Java CrossValidatorModel. Used for ML persistence.\n\n        Returns\n        -------\n        py4j.java_gateway.JavaObject\n            Java object equivalent to this instance.\n        \"\"\"\n\n        sc = SparkContext._active_spark_context\n        _java_obj = JavaParams._new_java_obj(\"org.apache.spark.ml.tuning.CrossValidatorModel\",\n                                             self.uid,\n                                             self.bestModel._to_java(),\n                                             _py2java(sc, self.avgMetrics))\n        estimator, epms, evaluator = super(CrossValidatorModel, self)._to_java_impl()\n\n        params = {\n            \"evaluator\": evaluator,\n            \"estimator\": estimator,\n            \"estimatorParamMaps\": epms,\n            \"numFolds\": self.getNumFolds(),\n            \"foldCol\": self.getFoldCol(),\n            \"seed\": self.getSeed(),\n        }\n        for param_name, param_val in params.items():\n            java_param = _java_obj.getParam(param_name)\n            pair = java_param.w(param_val)\n            _java_obj.set(pair)\n\n        if self.subModels is not None:\n            java_sub_models = [[sub_model._to_java() for sub_model in fold_sub_models]\n                               for fold_sub_models in self.subModels]\n            _java_obj.setSubModels(java_sub_models)\n        return _java_obj"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bedb2de0-317a-4e47-b503-b8c3bbe8d0f3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"custom_cv_module","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":632558266979041}},"nbformat":4,"nbformat_minor":0}
